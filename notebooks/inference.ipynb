{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcf74c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Great lipstick, love the color!', 'prediction': {'label': 'positive', 'label_id': 2, 'confidence': 0.4483020305633545}, 'probabilities': {'negative': 0.2981082499027252, 'neutral': 0.2535897195339203, 'positive': 0.4483020305633545}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')  \n",
    "\n",
    "from ml.inference import SentimentPredictor\n",
    "\n",
    "predictor = SentimentPredictor()\n",
    "result = predictor.predict(\"Great lipstick, love the color!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec617676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING DIFFERENT SENTIMENTS ===\n",
      "\n",
      "Positive example:\n",
      "Text: Absolutely amazing! Best purchase ever!\n",
      "Prediction: {'label': 'positive', 'label_id': 2, 'confidence': 0.4517734944820404}\n",
      "\n",
      "Negative example:\n",
      "Text: Terrible product. Complete waste of money.\n",
      "Prediction: {'label': 'positive', 'label_id': 2, 'confidence': 0.3967611491680145}\n",
      "\n",
      "Neutral example:\n",
      "Text: It's okay, nothing special.\n",
      "Prediction: {'label': 'positive', 'label_id': 2, 'confidence': 0.3895520567893982}\n",
      "\n",
      "Uncertain example:\n",
      "Text: I don't know how I feel about this.\n",
      "Prediction: {'label': 'positive', 'label_id': 2, 'confidence': 0.39134159684181213}\n",
      "\n",
      "Empty string:\n",
      "Text: ''\n",
      "Prediction: {'label': 'positive', 'label_id': 2, 'confidence': 0.4155731201171875}\n"
     ]
    }
   ],
   "source": [
    "# 1. Test different sentiment examples\n",
    "print(\"=== TESTING DIFFERENT SENTIMENTS ===\\n\")\n",
    "\n",
    "# Clearly positive\n",
    "result1 = predictor.predict(\"Absolutely amazing! Best purchase ever!\")\n",
    "print(\"Positive example:\")\n",
    "print(f\"Text: {result1['text']}\")\n",
    "print(f\"Prediction: {result1['prediction']}\")\n",
    "print()\n",
    "\n",
    "# Clearly negative\n",
    "result2 = predictor.predict(\"Terrible product. Complete waste of money.\")\n",
    "print(\"Negative example:\")\n",
    "print(f\"Text: {result2['text']}\")\n",
    "print(f\"Prediction: {result2['prediction']}\")\n",
    "print()\n",
    "\n",
    "# Neutral/mixed\n",
    "result3 = predictor.predict(\"It's okay, nothing special.\")\n",
    "print(\"Neutral example:\")\n",
    "print(f\"Text: {result3['text']}\")\n",
    "print(f\"Prediction: {result3['prediction']}\")\n",
    "print()\n",
    "\n",
    "# Edge case - uncertain\n",
    "result4 = predictor.predict(\"I don't know how I feel about this.\")\n",
    "print(\"Uncertain example:\")\n",
    "print(f\"Text: {result4['text']}\")\n",
    "print(f\"Prediction: {result4['prediction']}\")\n",
    "print()\n",
    "\n",
    "# Empty string\n",
    "result5 = predictor.predict(\"\")\n",
    "print(\"Empty string:\")\n",
    "print(f\"Text: '{result5['text']}'\")\n",
    "print(f\"Prediction: {result5['prediction']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8016fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARING PREDICTION METHODS ===\n",
      "\n",
      "Full result: {'text': 'Great lipstick!', 'prediction': {'label': 'positive', 'label_id': 2, 'confidence': 0.45110511779785156}, 'probabilities': {'negative': 0.29564446210861206, 'neutral': 0.2532504200935364, 'positive': 0.45110511779785156}}\n",
      "\n",
      "Probabilities only: [0.29564446 0.25325042 0.45110512]\n",
      "\n",
      "Label only: positive\n"
     ]
    }
   ],
   "source": [
    "# 2. Compare prediction methods\n",
    "print(\"\\n=== COMPARING PREDICTION METHODS ===\\n\")\n",
    "\n",
    "text = \"Great lipstick!\"\n",
    "\n",
    "# Full prediction\n",
    "full_result = predictor.predict(text)\n",
    "print(f\"Full result: {full_result}\\n\")\n",
    "\n",
    "# Just probabilities\n",
    "probs = predictor.predict_proba(text)\n",
    "print(f\"Probabilities only: {probs}\\n\")\n",
    "\n",
    "# Just label\n",
    "label = predictor.get_label(text)\n",
    "print(f\"Label only: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c1c7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODEL INTERNALS ===\n",
      "\n",
      "Device: cpu\n",
      "Model on: cpu\n",
      "Model in eval mode: True\n",
      "Number of parameters: 66,365,187\n"
     ]
    }
   ],
   "source": [
    "# 4. Model internals\n",
    "print(\"\\n=== MODEL INTERNALS ===\\n\")\n",
    "\n",
    "print(f\"Device: {predictor.device}\")\n",
    "print(f\"Model on: {next(predictor.model.parameters()).device}\")\n",
    "print(f\"Model in eval mode: {not predictor.model.training}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in predictor.model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9c02049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ERROR HANDLING TESTS ===\n",
      "\n",
      "None input error: ValueError: You need to specify either `text` or `text_target`.\n",
      "Number input error: ValueError: text input must be of type `str` (single example), `list[str]` (batch or single pretokenized example) or `list[list[str]]` (batch of pretokenized examples).\n",
      "Very long text (10000 chars): Worked! Confidence: 0.387\n"
     ]
    }
   ],
   "source": [
    "# 5. Error handling\n",
    "print(\"\\n=== ERROR HANDLING TESTS ===\\n\")\n",
    "\n",
    "# Test None input\n",
    "try:\n",
    "    predictor.predict(None)\n",
    "    print(\"None input: Worked!\")\n",
    "except Exception as e:\n",
    "    print(f\"None input error: {type(e).__name__}: {e}\")\n",
    "\n",
    "# Test number input\n",
    "try:\n",
    "    predictor.predict(123)\n",
    "    print(\"Number input: Worked!\")\n",
    "except Exception as e:\n",
    "    print(f\"Number input error: {type(e).__name__}: {e}\")\n",
    "\n",
    "# Test very long text\n",
    "try:\n",
    "    long_text = \"A\" * 10000\n",
    "    result = predictor.predict(long_text)\n",
    "    print(f\"Very long text (10000 chars): Worked! Confidence: {result['prediction']['confidence']:.3f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Long text error: {type(e).__name__}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csa (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
